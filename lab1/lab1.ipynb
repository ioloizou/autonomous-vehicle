{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'visualization.py')\n",
    "sys.path.insert(0, 'utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/user/ECN_AUVE_labs/scenario1/meta/Town01_type001_subtype0001_scenario00003.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# /!\\ Before running the lab make sure every additional libraries is installed \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Import local libraries\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/ECN_AUVE_labs/lab1/utils.py:34\u001b[0m\n\u001b[1;32m     30\u001b[0m file_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(osp\u001b[38;5;241m.\u001b[39mjoin(root_path,\n\u001b[1;32m     31\u001b[0m                                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mego_vehicle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, scenario) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/*\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m frame_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mosp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mscenario\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     35\u001b[0m             lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     36\u001b[0m line \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/user/ECN_AUVE_labs/scenario1/meta/Town01_type001_subtype0001_scenario00003.txt'"
     ]
    }
   ],
   "source": [
    "# /!\\ Before running the lab make sure every additional libraries is installed \n",
    "\n",
    "# Import local libraries\n",
    "from visualization import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is about showing measurements made by the Intelligent Road-Side Unit (IRSU) positioned at the center of the intersection:\n",
    "- 1 point clouds collected by a 32-channel LiDAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions you need to modify are located in:\n",
    "-  box_to_corner -> visualization.py\n",
    "\n",
    "-  get_boxes_in_actor_frame -> utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8)\n"
     ]
    }
   ],
   "source": [
    "n_frame = 0\n",
    "actor = 'ego_vehicle'\n",
    "\n",
    "irsu_points = get_point_cloud(n_frame, actor)\n",
    "irsu_boxes = get_boxes_in_actor_frame(n_frame, actor)\n",
    "print(irsu_boxes.shape)\n",
    "box_colors = CLASS_COLORS[irsu_boxes[:, -1].astype(np.int32)]\n",
    "\n",
    "\n",
    "show_objects(irsu_points[:,:3], irsu_boxes[:,:7], box_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise demonstrates how the field of view and perception range of a vehicle can be enhanced by receiving data from other vehicles and the IRSU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions you need to modify are:\n",
    "-  box_to_corner (already done in task 1) -> visualization.py\n",
    "-  get_available_point_clouds, get_available_boxes_in_ego_frame, get_boxes_in_actor_frame(already done in task 1) -> utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frame = 0\n",
    "actors = [\"ego_vehicle\" ,\"other_vehicle\",   \"ego_vehicle_behind\",\"other_vehicle_behind\" ,\"infrastructure\",]#\n",
    "\n",
    "merged_points = get_available_point_clouds(n_frame, actors)\n",
    "irsu_boxes = get_available_boxes_in_ego_frame(n_frame, actors)\n",
    "box_colors = CLASS_COLORS[irsu_boxes[:, -1].astype(np.int32)]\n",
    "\n",
    "show_objects(merged_points, irsu_boxes[:,:7], box_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a BEV occupancy grid of the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A main challenge in perception on point clouds is their unordered nature which hinders the application of the Convolution operation, thus preventing the use of many wonders in the world of image-based perception. An effective way to get around this challenge is to convert point clouds to BEV images. In other word, to look at a point cloud from the top-view which is what you are going to do in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions you need to modify are :\n",
    "-  box_to_pixels, points_to_pixels-> visualization.py\n",
    "-  filter_points -> utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f85ecbe23a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n_frame = 0\n",
    "actors = [\"ego_vehicle\" ,\"other_vehicle\",   \"ego_vehicle_behind\",\"other_vehicle_behind\",\"infrastructure\",]\n",
    "merged_points = get_available_point_clouds(n_frame, actors)\n",
    "irsu_boxes = get_available_boxes_in_ego_frame(n_frame, actors)\n",
    "box_colors = CLASS_COLORS[irsu_boxes[:, -1].astype(np.int32)]\n",
    "\n",
    "# ------------------ Get Waypoints that belongs to the ground floor ------------------\n",
    "points_range = np.array([-50, -50, -25, 50, 50, 0.01])  # xmin, ymin, zmin, xmax, ymax, zmax (meters) around ego_vehicle\n",
    "\n",
    "filtered_points = filter_points(merged_points, points_range)\n",
    "show_objects(filtered_points, irsu_boxes[:,:7], box_colors)\n",
    "\n",
    "# ------------------  Build BEV image  ------------------  \n",
    "bev_resolution = 0.1 # meters / pixel\n",
    "bev_imsize = np.ceil((points_range[3: 5] - points_range[:2]) / bev_resolution).astype(int)  # (width, height)\n",
    "bev_occupancy = np.zeros((bev_imsize[1], bev_imsize[0]))\n",
    "\n",
    "# ------------------  Project bbox of actors on the image  ------------------  \n",
    "box_mask = box_to_pixels(irsu_boxes[:,:7], bev_imsize, bev_resolution)\n",
    "bev_occupancy[box_mask > 0] = 255\n",
    "\n",
    "# ------------------  Project navigable space on the image ------------------  \n",
    "navigable_space = points_to_pixels(filtered_points, bev_imsize, bev_resolution)\n",
    "\n",
    "for pixel in navigable_space:\n",
    "    bev_occupancy[pixel[1], pixel[0]] = 150\n",
    "\n",
    "\n",
    "plt.imshow(bev_occupancy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째4: \n",
    "Segment points according to object's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each detection is attached with one class label, use it to filter out the detections of interest (e.g. vehicles, pedestrians, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
