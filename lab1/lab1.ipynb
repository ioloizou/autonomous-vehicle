{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'visualization.py')\n",
    "sys.path.insert(0, 'utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# /!\\ Before running the lab make sure every additional libraries is installed \n",
    "\n",
    "# Import local libraries\n",
    "from visualization import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is about showing measurements made by the Intelligent Road-Side Unit (IRSU) positioned at the center of the intersection:\n",
    "- 1 point clouds collected by a 32-channel LiDAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions you need to modify are located in:\n",
    "-  box_to_corner -> visualization.py\n",
    "\n",
    "-  get_boxes_in_actor_frame -> utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.18121004e+00  1.99411726e+00  1.38058162e+00  4.40752788e-05\n",
      "   0.00000000e+00]\n",
      " [ 4.67363882e+00  1.81181252e+00  1.44194734e+00  2.68457197e-01\n",
      "   0.00000000e+00]\n",
      " [ 4.67363882e+00  1.81181252e+00  1.44194734e+00 -3.14112847e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.46804142e+00  2.89108825e+00  3.82741237e+00 -1.56996116e+00\n",
      "   1.00000000e+00]\n",
      " [ 4.61100578e+00  2.24171329e+00  1.66727591e+00 -1.57027595e+00\n",
      "   0.00000000e+00]\n",
      " [ 4.85570860e+00  2.03275657e+00  1.64935935e+00  1.57116772e+00\n",
      "   0.00000000e+00]\n",
      " [ 3.75357777e-01  3.75357777e-01  1.86000001e+00 -3.13430040e+00\n",
      "   3.00000000e+00]\n",
      " [ 3.75357777e-01  3.75357777e-01  1.86000001e+00  1.79648306e-01\n",
      "   3.00000000e+00]\n",
      " [ 3.75357777e-01  3.75357777e-01  1.86000001e+00 -1.82331759e+00\n",
      "   3.00000000e+00]\n",
      " [ 3.75357777e-01  3.75357777e-01  1.86000001e+00 -3.11824621e+00\n",
      "   3.00000000e+00]]\n",
      "(10, 3)\n",
      "(10, 5)\n",
      "(10, 8)\n"
     ]
    }
   ],
   "source": [
    "n_frame = 0\n",
    "actor = 'ego_vehicle'\n",
    "\n",
    "irsu_points = get_point_cloud(n_frame, actor)\n",
    "irsu_boxes = get_boxes_in_actor_frame(n_frame, actor)\n",
    "print(irsu_boxes.shape)\n",
    "box_colors = CLASS_COLORS[irsu_boxes[:, -1].astype(np.int32)]\n",
    "\n",
    "\n",
    "show_objects(irsu_points[:,:3], irsu_boxes[:,:7], box_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise demonstrates how the field of view and perception range of a vehicle can be enhanced by receiving data from other vehicles and the IRSU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions you need to modify are:\n",
    "-  box_to_corner (already done in task 1) -> visualization.py\n",
    "-  get_available_point_clouds, get_available_boxes_in_ego_frame, get_boxes_in_actor_frame(already done in task 1) -> utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "(10, 5)\n",
      "(11, 3)\n",
      "(11, 5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 8 and the array at index 1 has size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m actors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mego_vehicle\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother_vehicle\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mego_vehicle_behind\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother_vehicle_behind\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrastructure\u001b[39m\u001b[38;5;124m\"\u001b[39m,]\u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m merged_points \u001b[38;5;241m=\u001b[39m get_available_point_clouds(n_frame, actors)\n\u001b[0;32m----> 5\u001b[0m irsu_boxes \u001b[38;5;241m=\u001b[39m \u001b[43mget_available_boxes_in_ego_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m box_colors \u001b[38;5;241m=\u001b[39m CLASS_COLORS[irsu_boxes[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)]\n\u001b[1;32m      8\u001b[0m show_objects(merged_points, irsu_boxes[:,:\u001b[38;5;241m7\u001b[39m], box_colors)\n",
      "File \u001b[0;32m~/ECN_AUVE_labs/lab1/utils.py:168\u001b[0m, in \u001b[0;36mget_available_boxes_in_ego_frame\u001b[0;34m(n_frame, actors)\u001b[0m\n\u001b[1;32m    166\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(boxes)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m    167\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m apply_tf(actor_to_world \u001b[38;5;241m@\u001b[39m world_to_ego, boxes)\n\u001b[0;32m--> 168\u001b[0m     available_boxes_in_ego_frame \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mavailable_boxes_in_ego_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m boxes\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 8 and the array at index 1 has size 3"
     ]
    }
   ],
   "source": [
    "n_frame = 0\n",
    "actors = [\"ego_vehicle\" ,\"other_vehicle\",   \"ego_vehicle_behind\",\"other_vehicle_behind\" ,\"infrastructure\",]#\n",
    "\n",
    "merged_points = get_available_point_clouds(n_frame, actors)\n",
    "irsu_boxes = get_available_boxes_in_ego_frame(n_frame, actors)\n",
    "box_colors = CLASS_COLORS[irsu_boxes[:, -1].astype(np.int32)]\n",
    "\n",
    "show_objects(merged_points, irsu_boxes[:,:7], box_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a BEV occupancy grid of the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A main challenge in perception on point clouds is their unordered nature which hinders the application of the Convolution operation, thus preventing the use of many wonders in the world of image-based perception. An effective way to get around this challenge is to convert point clouds to BEV images. In other word, to look at a point cloud from the top-view which is what you are going to do in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions you need to modify are :\n",
    "-  box_to_pixels, points_to_pixels-> visualization.py\n",
    "-  filter_points -> utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f85ecbe23a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n_frame = 0\n",
    "actors = [\"ego_vehicle\" ,\"other_vehicle\",   \"ego_vehicle_behind\",\"other_vehicle_behind\",\"infrastructure\",]\n",
    "merged_points = get_available_point_clouds(n_frame, actors)\n",
    "irsu_boxes = get_available_boxes_in_ego_frame(n_frame, actors)\n",
    "box_colors = CLASS_COLORS[irsu_boxes[:, -1].astype(np.int32)]\n",
    "\n",
    "# ------------------ Get Waypoints that belongs to the ground floor ------------------\n",
    "points_range = np.array([-50, -50, -25, 50, 50, 0.01])  # xmin, ymin, zmin, xmax, ymax, zmax (meters) around ego_vehicle\n",
    "\n",
    "filtered_points = filter_points(merged_points, points_range)\n",
    "show_objects(filtered_points, irsu_boxes[:,:7], box_colors)\n",
    "\n",
    "# ------------------  Build BEV image  ------------------  \n",
    "bev_resolution = 0.1 # meters / pixel\n",
    "bev_imsize = np.ceil((points_range[3: 5] - points_range[:2]) / bev_resolution).astype(int)  # (width, height)\n",
    "bev_occupancy = np.zeros((bev_imsize[1], bev_imsize[0]))\n",
    "\n",
    "# ------------------  Project bbox of actors on the image  ------------------  \n",
    "box_mask = box_to_pixels(irsu_boxes[:,:7], bev_imsize, bev_resolution)\n",
    "bev_occupancy[box_mask > 0] = 255\n",
    "\n",
    "# ------------------  Project navigable space on the image ------------------  \n",
    "navigable_space = points_to_pixels(filtered_points, bev_imsize, bev_resolution)\n",
    "\n",
    "for pixel in navigable_space:\n",
    "    bev_occupancy[pixel[1], pixel[0]] = 150\n",
    "\n",
    "\n",
    "plt.imshow(bev_occupancy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task n째4: \n",
    "Segment points according to object's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each detection is attached with one class label, use it to filter out the detections of interest (e.g. vehicles, pedestrians, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
