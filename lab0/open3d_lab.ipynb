{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# /!\\ Before running the lab make sure every additional libraries is installed \n",
    "\n",
    "# Import local libraries\n",
    "from utils import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading of one LiDAR scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frame = 0\n",
    "actor = 'ego_vehicle'\n",
    "\n",
    "points = get_point_cloud(n_frame, actor)\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "flag_display = True\n",
    "o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voxel Down sampling\n",
    "\n",
    "To reduce the number of points and accelerate the computation use the function _voxel_down_sample()_ of open3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "downpcd =  pcd.voxel_down_sample(0.1) # ToDo (Replace this line) \n",
    "\n",
    "if flag_display:\n",
    "    o3d.visualization.draw_geometries([downpcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normals estimation\n",
    "We would like to detect opstacles, to do that the first step is to estimate normals to obtain the local orientation of the point cloud.\n",
    "\n",
    "Use the function _estimate_normals()_ of open3D to estimate this normals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo estimate the normals\n",
    "\n",
    "# Estimating normals\n",
    "downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.4, max_nn=100))\n",
    "\n",
    "if flag_display:\n",
    "    o3d.visualization.draw_geometries([downpcd], point_show_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "downpcd.colors = o3d.utility.Vector3dVector(np.abs(np.array(downpcd.normals)))\n",
    "\n",
    "if flag_display:\n",
    "    o3d.visualization.draw_geometries([downpcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground and objects segmentation\n",
    "\n",
    "Based on the height of each point, the local orientation of the points cloud arround this point and eventually the variation of this orientation filter the ground to obtain a new points cloud whith only the ground points and another one with only the objects on top of this ground.\n",
    "\n",
    "For both of these new points clouds you can also filter the points corresponding to the roof of the ego vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the point cloud is:  (23060, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of pcd\n",
    "print(\"The shape of the point cloud is: \", np.array(downpcd.points).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the original point cloud is:  (23060, 3)\n",
      "The shape of the ground point cloud is:  (10431, 3)\n"
     ]
    }
   ],
   "source": [
    "def ground_filtering(pcd):\n",
    "    normals = np.asarray(pcd.normals)  # Convert to NumPy array\n",
    "    points = np.asarray(pcd.points)  # Convert to NumPy array\n",
    "    height = 0.3  # Height threshold\n",
    "\n",
    "\n",
    "    # Get the norm of x and y of normals    \n",
    "    norm_x_y = np.linalg.norm(normals[:, :2], axis=1)\n",
    "    mask = (norm_x_y < 0.4) & (points[:, 2] < height)\n",
    "\n",
    "    pcd_ground = pcd.select_by_index(np.where(mask)[0])\n",
    "    return pcd_ground\n",
    "\n",
    "pcd_ground = ground_filtering(downpcd)\n",
    "\n",
    "# Check the difference between the original point cloud and the ground point cloud\n",
    "print(\"The shape of the original point cloud is: \", np.array(downpcd.points).shape)\n",
    "print(\"The shape of the ground point cloud is: \", np.array(pcd_ground.points).shape)\n",
    "\n",
    "if flag_display:\n",
    "    o3d.visualization.draw_geometries([pcd_ground])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objects_filtering(pcd):\n",
    "    normals = np.asarray(pcd.normals)  # Convert to NumPy array\n",
    "    points = np.asarray(pcd.points)  # Convert to NumPy array\n",
    "    height = 0.3  # Height threshold\n",
    "\n",
    "\n",
    "    # Get the norm of x and y of normals    \n",
    "    norm_x_y = np.linalg.norm(normals[:, :2], axis=1)\n",
    "    mask = (norm_x_y > 0.4) | (points[:, 2] > height)\n",
    "\n",
    "    pcd_objects = pcd.select_by_index(np.where(mask)[0])\n",
    "    return pcd_objects\n",
    "\n",
    "pcd_objects = objects_filtering(downpcd)\n",
    "\n",
    "if flag_display:\n",
    "    o3d.visualization.draw_geometries([pcd_objects])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Now that the points of the objects are not connected to the ground anymore we can regroup all the points of the same object on one cluster.\n",
    "\n",
    "To do that, use the function _cluster_dbscan()_ of open3D to obtain the cluster id for each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precompute neighbors.[========================================] 100%\n",
      "The points cloud has 52 clusters=================> ] 95%\n"
     ]
    }
   ],
   "source": [
    "def clustering(pcd_objects):\n",
    "    \n",
    "    cluster_ids = np.array(pcd_objects.cluster_dbscan(eps=2., min_points=10, print_progress=True)) # ToDo (Replace this line)\n",
    "    \n",
    "    cluster_nb = cluster_ids.max()\n",
    "    colors = plt.get_cmap(\"tab20\")(cluster_ids / (cluster_nb if cluster_nb > 0 else 1))\n",
    "    colors[cluster_ids < 0] = 0\n",
    "    pcd_objects.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "\n",
    "    # To understand the part of car we use that lidar which is at the origin and then we use the norm of the vector to exlude the points that are too close to the origin with a specified threshold\n",
    "    mask = np.linalg.norm(np.asarray(pcd_objects.points), axis=1) > 3\n",
    "    # Removing the points that make the mask true\n",
    "    pcd_objects = pcd_objects.select_by_index(np.where(mask)[0])\n",
    "\n",
    "    return pcd_objects, cluster_ids\n",
    "\n",
    "pcd_objects, cluster_ids = clustering(pcd_objects)\n",
    "\n",
    "print(\"The points cloud has\", cluster_ids.max() + 1, \"clusters\")\n",
    "\n",
    "if flag_display:\n",
    "    o3d.visualization.draw_geometries([pcd_objects])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding Boxes estimation\n",
    "Estimate for each of these clusters its bounding box. You can use the function _get_axis_aligned_bounding_box()_ or _get_oriented_bounding_box()_ of open3D.\n",
    "\n",
    "What are the limits of these functions ?\n",
    "\n",
    "You can keep only the small bounding boxes correponding to the small objects (such as vehicles or pedestrians and not buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_boxes(pcd_objects, cluster_ids):\n",
    "    # Define size constraints for car-sized bounding boxes. No need for human since it will be smaller\n",
    "    car_size = np.array([10., 10., 10.])   # Example dimensions (length, width, height)\n",
    "    \n",
    "    # Bounding boxes\n",
    "    boxes = []\n",
    "    \n",
    "    # Get the number of clusters\n",
    "    max_label = cluster_ids.max()\n",
    "    \n",
    "    # Iterate through each cluster and compute the bounding box\n",
    "    for i in range(max_label + 1):\n",
    "        cluster_indices = np.where(cluster_ids == i)[0]\n",
    "        cluster = pcd_objects.select_by_index(cluster_indices)\n",
    "        \n",
    "        # Compute the oriented bounding box (OBB)\n",
    "        obb = cluster.get_oriented_bounding_box()\n",
    "        \n",
    "        # Check if the bounding box is within the size constraints for humans or cars\n",
    "        # and if the bounding box is placed lower than 1 meter from the ground\n",
    "        if np.all(obb.extent <= car_size) and obb.get_min_bound()[2] <= 0.4:\n",
    "            obb.color = (1, 0, 0)  # Red color for OBB\n",
    "            boxes.append(obb)\n",
    "            \n",
    "    return boxes\n",
    "\n",
    "boxes = cluster_boxes(pcd_objects, cluster_ids)\n",
    "\n",
    "obj_to_display = list(boxes)\n",
    "obj_to_display.extend([pcd_objects])\n",
    "\n",
    "flag_display = True\n",
    "if flag_display:\n",
    "    o3d.visualization.draw_geometries(obj_to_display)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objects detection and tracking on LiDAR scans\n",
    "\n",
    "Applied the previous functions on the different scan to estimate the bounding boxes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Apply the same process for different scans  \n",
    "n_frame = 1\n",
    "actor = 'ego_vehicle'\n",
    "points = get_point_cloud(n_frame, actor)\n",
    "\n",
    "pcd_next = o3d.geometry.PointCloud()\n",
    "pcd_next.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "downpcd_next = pcd_next.voxel_down_sample(0.1) # ToDo (Replace this line)\n",
    "\n",
    "downpcd_next.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.4, max_nn=100))\n",
    "\n",
    "downpcd_next.colors = o3d.utility.Vector3dVector(np.abs(np.array(downpcd_next.normals)))\n",
    "\n",
    "pcd_ground_next = ground_filtering(downpcd_next)\n",
    "\n",
    "pcd_objects_next = objects_filtering(downpcd_next)\n",
    "\n",
    "pcd_objects_next, cluster_ids_next = clustering(pcd_objects_next)\n",
    "\n",
    "boxes_next = cluster_boxes(pcd_objects_next, cluster_ids_next)\n",
    "\n",
    "obj_to_display_next = list(boxes_next)\n",
    "obj_to_display_next.extend([pcd_objects_next])\n",
    "\n",
    "# Print the number of cluster and boxes\n",
    "print(\"The points cloud has\", cluster_ids_next.max() + 1, \"clusters\")\n",
    "print(\"The number of boxes is: \", len(boxes_next))\n",
    "\n",
    "if True:\n",
    "    o3d.visualization.draw_geometries(obj_to_display_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Bounding boxes association\n",
    "\n",
    "Create a function to associate the bounding boxes of the current time to the one of the previous time based the shortest distances of there centers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_bounding(previous_boxes, current_boxes):\n",
    "    # Associate bounding boxes between the two frames\n",
    "    # For each bounding box in the first frame, find the closest bounding box in the second frame\n",
    "    # If the bounding boxes are close enough, consider them as the same object\n",
    "    \n",
    "    # Define a threshold for the distance between bounding boxes\n",
    "    distance_threshold = 1000\n",
    "    \n",
    "    # List to store the associated bounding boxes\n",
    "    associated_boxes = []\n",
    "    \n",
    "    # Iterate through each bounding box in the previous frame\n",
    "    for prev_box in previous_boxes:\n",
    "        min_distance = distance_threshold\n",
    "        associated_box = None\n",
    "        \n",
    "        # Iterate through each bounding box in the current frame\n",
    "        for curr_box in current_boxes:\n",
    "            # Compute the distance between the centers of the bounding boxes\n",
    "            distance = np.linalg.norm(prev_box.get_center() - curr_box.get_center())\n",
    "            \n",
    "            # Check if the distance is smaller than the threshold\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                associated_box = curr_box\n",
    "        \n",
    "        # If an associated bounding box was found, add it to the list\n",
    "        if associated_box is not None:\n",
    "            associated_boxes.append(associated_box)\n",
    "    \n",
    "    print(associated_boxes)\n",
    "    \n",
    "\n",
    "associate_bounding(boxes, boxes_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Bounding boxes orientation estimation\n",
    "Based on these association estimate the orientation of there motion to correct the orientation of the bounding boxes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Points cloud mapping\n",
    "Build a map by accumulating the different points cloud and removing the moving objects (keep the cluster id and add a new one for the ground points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Iterative Closest Point tracking\n",
    "To better associate the clusters you can also use the function _icp()_ of open3D on each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Function to create a coordinate frame\n",
    "# def create_coordinate_frame(size=1.0, origin=[0, 0, 0]):\n",
    "#     return o3d.geometry.TriangleMesh.create_coordinate_frame(size=size, origin=origin)\n",
    "\n",
    "# # Initialize Open3D Visualizer\n",
    "# if flag_display:\n",
    "#     vis = o3d.visualization.Visualizer()\n",
    "#     vis.create_window()\n",
    "\n",
    "#     # Add the origin coordinate frame to the visualizer\n",
    "#     origin_frame = create_coordinate_frame(size=6., origin=[0, 0, 0])\n",
    "#     vis.add_geometry(origin_frame)\n",
    "\n",
    "\n",
    "# for n_frame in range(nb_frames):\n",
    "    \n",
    "#     # Read point cloud\n",
    "#     points = get_point_cloud(n_frame, actor)\n",
    "#     pcd = o3d.geometry.PointCloud()\n",
    "#     pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "#     # Voxel down sampling\n",
    "#     downpcd = pcd.voxel_down_sample(0.1) # ToDo (Replace this line)\n",
    "    \n",
    "#     # Transform points cloud from the LiDAR to the world frame\n",
    "#     tf = get_tf_lidar2world(actor, n_frame)\n",
    "#     # ToDo applied this transformation to the points cloud\n",
    "#     pcd.transform(tf)\n",
    "\n",
    "#     # Estimate normals\n",
    "#     #ToDo estimate the normals\n",
    "#     downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.4, max_nn=100))\n",
    "#     downpcd.colors = o3d.utility.Vector3dVector(np.abs(np.array(downpcd.normals)))\n",
    "    \n",
    "\n",
    "#     # Filter ground points\n",
    "#     pcd_ground = ground_filtering(downpcd)\n",
    "    \n",
    "#     # Filter objects points\n",
    "#     pcd_objects = objects_filtering(downpcd)\n",
    "    \n",
    "#     # Clustering\n",
    "#     pcd_objects, cluster_ids = clustering(pcd_objects)\n",
    "    \n",
    "#     if flag_display:\n",
    "#         # Clear previous geometries and add new point cloud to visualizer\n",
    "#         vis.clear_geometries()\n",
    "#         vis.add_geometry(pcd_objects)\n",
    "        \n",
    "#         # Re-add the origin coordinate frame to the visualizer\n",
    "#         vis.add_geometry(origin_frame)\n",
    "\n",
    "#         # Update the visualizer to show the new point cloud\n",
    "#         vis.poll_events()\n",
    "#         vis.update_renderer()\n",
    "\n",
    "#         # Wait before updating the points cloud (adjust time as needed)\n",
    "#         time.sleep(0.1)\n",
    "\n",
    "# if flag_display:\n",
    "#     # Close the visualizer\n",
    "#     vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
